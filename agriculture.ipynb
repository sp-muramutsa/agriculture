{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fd26a6e-3676-4847-9a47-18ce43fb83e0",
   "metadata": {},
   "source": [
    "# Sowing Success: How Machine Learning Helps Farmers Select the Best Crops\n",
    "\n",
    "\n",
    "<img src=\"https://cdn11.bigcommerce.com/s-jl3t5tg/product_images/uploaded_images/rwanda7.jpg\" width=\"800\" height=\"200\"/>\n",
    "\n",
    "Measuring essential soil metrics such as nitrogen, phosphorous, potassium levels, and pH value is an important aspect of assessing soil condition. However, it can be an expensive and time-consuming process, which can cause farmers to prioritize which metrics to measure based on their budget constraints.\n",
    "\n",
    "Farmers have various options when it comes to deciding which crop to plant each season. Their primary objective is to maximize the yield of their crops, taking into account different factors. One crucial factor that affects crop growth is the condition of the soil in the field, which can be assessed by measuring basic elements such as nitrogen and potassium levels. Each crop has an ideal soil condition that ensures optimal growth and maximum yield.\n",
    "\n",
    "A farmer reached out to you as a machine learning expert for assistance in selecting the best crop for his field. They've provided you with a dataset called soil_measures.csv, which contains:\n",
    "\n",
    "- \"N\": Nitrogen content ratio in the soil\n",
    "- \"P\": Phosphorous content ratio in the soil\n",
    "- \"K\": Potassium content ratio in the soil\n",
    "- \"pH\" value of the soil\n",
    "- \"crop\": categorical values that contain various crops (target variable).\n",
    "Each row in this dataset represents various measures of the soil in a particular field. Based on these measurements, the crop specified in the \"crop\" column is the optimal choice for that field.\n",
    "\n",
    "In this project, we will build multi-class classification models to predict the type of \"crop\" and identify the single most importance feature for predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e86893-fa6c-434d-8f38-082969068dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7211fd4-a1e7-4a79-ab56-3260d077d7a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'soil_measures.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m crops = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msoil_measures.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'soil_measures.csv'"
     ]
    }
   ],
   "source": [
    "crops = pd.read_csv(\"soil_measures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c828613-b4f9-4a27-8816-49037c5ba769",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559ba13-d74a-40dc-b274-032cec53afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"N\", \"P\", \"K\", \"ph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545dd6e-f47e-4bc7-acbd-fb053ce256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crops[features]\n",
    "y = crops[\"crop\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394ac84-7f23-4538-93b0-7fc73786b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307851d8-5d6b-4027-9b03-b71126479784",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279687e3-748d-485c-8a0a-2ac459cd1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=features)\n",
    "X_test = pd.DataFrame(X_test, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47e5d2-1867-4703-bdde-0bbe85eab359",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver=\"lbfgs\")\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fe20e-8d0b-4b6b-a40d-25481982bb1e",
   "metadata": {},
   "source": [
    "## Feature Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb0763-6b26-4cdd-83fd-e83f872a0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635bf28-3c25-4526-831a-9f0d61456a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_means = np.mean(abs(log_reg.coef_), axis=0)\n",
    "for feature, mean in zip(features, coefficient_means):\n",
    "    print(f\"The mean coefficient of the feature {feature} is {mean:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab0b37-16b0-4629-841f-bfe4b5baff45",
   "metadata": {},
   "source": [
    "We now have the relative importance, assuming linear relationships. However, this doesn't measure how prediction performance would change if a feature was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b536865-a134-468e-8941-f24854b8431c",
   "metadata": {},
   "source": [
    "## Model Performance when trained on each feature: F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff6f80-251b-49c9-b0d5-e22c86d99c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}\n",
    "\n",
    "for feature in features:\n",
    "    log = LogisticRegression(solver=\"lbfgs\", max_iter=300)\n",
    "    log.fit(X_train[[feature]], y_train)\n",
    "    y_pred = log.predict(X_test[[feature]])\n",
    "\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average=\"macro\")\n",
    "    performance[feature] = f1\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e78347-e70d-45e3-b6f0-3239923dc686",
   "metadata": {},
   "source": [
    "It is clear that Potassium, \"K\" has the highest raw predictive power for determining optimal crop choice for a field. Nitrogen, \"N\" follows closely, while the PH balance of the soil looks almost insiginificant. However, we need to take into accound the relationships between the feaures themselves. Maybe PH + P exudes more influence than N alone. And that is why we are going to explore SHAP. SHAP (SHapley Additive exPlanations) is one of the most powerful and interpretable tools to understand feature importance and individual predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecff68-2380-4deb-b388-c34716bc79c0",
   "metadata": {},
   "source": [
    "## SHAP \n",
    "\"The core idea behind ShAP value based explanations of machine learning models is to use fair allocation results from cooperative game theory to allocate credit for a model’s output \n",
    "among its input features. In order to connect game theory with machine learning models, it is necessary to both match a model’s input features with players in a game, and also match the model function with the rules of the game. Since in game theory a player can join or not join a game, we need a way for a feature to “join” or “not join” a model.\" — Official docs\n",
    "https://shap.readthedocs.io/en/stable/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6260417-e345-49fd-b9f5-f70edbe4d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfa1af-3cbc-4da4-b5cd-e9b1953e2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(log_reg, X_train)\n",
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d8d7c-b19f-4432-8a65-829ebf77b084",
   "metadata": {},
   "source": [
    "### Individual Data Point Feature Contribution: Feature-wise contribution in the model's classification of a particular data point into a particular class. \n",
    "Waterfall plots are designed to display explanations for individual predictions. The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction.\n",
    "\n",
    "In this case, we are going to be choosing a data point at random, then explore each feature's individual contribution to the model's decision to classify it into a particular crop class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31679aec-003e-4860-874c-5c2f01be04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = shap_values.values.shape[2]\n",
    "n = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db95e42-2906-4a78-b15d-1c68bdad8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(4):\n",
    "    index = np.random.randint(n)  # Random data point\n",
    "    class_index = np.random.randint(num_classes)  # Random class index\n",
    "    class_name = le.inverse_transform([class_index])[0]  # Crop name from earlier LabelEncoder\n",
    "    \n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values[:, :, class_index],\n",
    "        base_values=shap_values.base_values[:, class_index],\n",
    "        data=X_train,\n",
    "        feature_names=features\n",
    "    )\n",
    "\n",
    "    shap.plots.waterfall(explanation[index], show=False)\n",
    "    plt.title(f\"Sample {index}, Class: {class_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a7da6-b643-4d49-b08b-d92b1bc98618",
   "metadata": {},
   "source": [
    "### Class-wise Feature Contribution: Feature-wise contribution in the model's classification of all points to a particular class. \n",
    "Now, let’s explore the model’s behavior crop-wise. For each of the five randomly selected crop classes out of our total of twenty-two, we will examine how the individual features influence the model’s decision to classify all data points that were classified into that specific crop class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201aa57-d2be-45ac-ae7a-f08181dfad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "\n",
    "for _ in range(5):\n",
    "    class_index = np.random.randint(num_classes)\n",
    "    class_name = le.classes_[class_index]\n",
    "    print(f\"SHAP summary plot for class: {class_name}\")\n",
    "    shap.summary_plot(\n",
    "        shap_values[:, :, class_index],  \n",
    "        X_train,                         # feature data\n",
    "        feature_names=features,\n",
    "        show=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca91497-fe62-4872-b812-38ac01bcb734",
   "metadata": {},
   "source": [
    "## Dependence Scatter Plot\n",
    "\n",
    "A dependence scatter plot illustrates how a single feature influences the model's predictions.\n",
    "In this case, the plot uses SHAP values aggregated across all 22 crop classes.\n",
    "\n",
    "To highlight potential interaction effects between features, the `color=explanation` argument is used. This reveals how the selected feature interacts with others—specifically, the one it most frequently pairs with in driving the prediction is shown on the right side of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c83c6-bce8-4f6e-aef3-05b61d724885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    shap.plots.scatter(explanation[:, feature], color=explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46c102-5808-4444-8308-00803d84a97d",
   "metadata": {},
   "source": [
    "## The bigger picture: How each feature influences classification accross all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8db6af-d1f8-4955-8fac-300c5d45a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate SHAP values across classes\n",
    "shap_means = np.mean(np.abs(shap_values.values), axis=2)  \n",
    "\n",
    "#Use mean base values \n",
    "base_vals = np.mean(shap_values.base_values, axis=1) \n",
    "\n",
    "exp = shap.Explanation(\n",
    "    values=shap_means,\n",
    "    base_values=base_vals,\n",
    "    data=X_train,\n",
    "    feature_names=features\n",
    ")\n",
    "\n",
    "shap.plots.bar(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
